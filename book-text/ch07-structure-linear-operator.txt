168

Advanced Linear Algebra

2) The elementary divisors and invariant factors of a matrix ( are the
elementary divisors and invariant factors, respectively, of the multiplication
operator ( :
ElemDivÂ²(Â³ ~ ElemDivÂ²( Â³

and

InvFactÂ²(Â³ ~ InvFactÂ²( Â³

We emphasize that the elementary divisors and invariant factors of an operator
or matrix are monic by definition. Thus, we no longer need to worry about
uniqueness up to associate.
Theorem 7.6 (The primary cyclic decomposition theorem for = Â³ Let = be
finite-dimensional and let  Â BÂ²= Â³ have minimal polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³
where the polynomials  Â²%Â³ are distinct monic primes.
1) (Primary decomposition) The - Â´%Âµ-module = is the direct sum
= ~ = l Ã„ l =
where
= ~

 Â²%Â³
= ~ Â¸# Â = Â“  Â² Â³Â²#Â³ ~ Â¹
 Â²%Â³

is a primary submodule of = of order  Â²%Â³. In vector space terms, = is a
 -invariant subspace of = and the minimal polynomial of  O= is
minÂ² O= Â³ ~  Â²%Â³
2) (Cyclic decomposition) Each primary summand = can be decomposed
into a direct sum
= ~ ÂºÂº#Ã Â»Â» l Ã„ l ÂºÂº#Ã Â»Â»


of  -cyclic submodules ÂºÂº#Ã Â»Â» of order  Ã Â²%Â³ with
 ~ Ã Â‚ Ã Â‚ Ã„ Â‚ Ã
In vector space terms, ÂºÂº#Ã Â»Â» is a  -cyclic subspace of = and the minimal
polynomial of OÂºÂº#Ã Â»Â» is


minÂ² OÂºÂº#Ã Â»Â» Â³ ~  Ã Â²%Â³
3) (The complete decomposition) This yields the decomposition of = into a
direct sum of  -cyclic subspaces
= ~ Â²ÂºÂº#Ã Â»Â» l Ã„ l ÂºÂº#Ã Â»Â»Â³ l Ã„ l Â²ÂºÂº#Ã Â»Â» l Ã„ l ÂºÂº#Ã Â»Â»Â³
4) (Elementary divisors and dimensions) The multiset of elementary divisors


Â¸ Ã Â²%Â³Â¹ is uniquely determined by  . If degÂ² Ã Â²%Â³Â³ ~ Ã , then the  -

The Structure of a Linear Operator

169

cyclic subspace ÂºÂº#Ã Â»Â» has  -cyclic basis
8Ã ~ 2#Ã Ã  #Ã Ã Ãƒ Ã  Ã c #Ã 3


and dimÂ²ÂºÂº#Ã Â»Â»Â³ ~ degÂ² Ã Â³. Hence,




dimÂ²= Â³ ~  degÂ² Ã Â³
~

We will call the basis
H ~  8Ã
Ã

for = the elementary divisor basis for = .
Recall that if = ~ ( l ) and if both ( and ) are  -invariant subspaces of = ,
the pair Â²(Ã )Â³ is said to reduce  . In module language, the pair Â²(Ã )Â³ reduces
 if ( and ) are submodules of = and
= ~ ( l )
We can now translate Theorem 6.15 into the current context.
Theorem 7.7 Let  Â BÂ²= Â³ and let
= ~ ( l )
1) The minimal polynomial of  is
 Â²%Â³ ~ lcmÂ² O( Â²%Â³Ã  O) Â²%Â³Â³
2) The primary cyclic decomposition of = is the direct sum of the primary
cyclic decompositons of ( and ) ; that is, if
( ~ ÂºÂºÃ Â»Â»

and ) ~ ÂºÂºÃ Â»Â»

are the primary cyclic decompositions of ( and ) , respectively, then
= ~ 4ÂºÂºÃ Â»Â»5 l 4ÂºÂºÃ Â»Â»5
is the primary cyclic decomposition of = .
3) The elementary divisors of  are
ElemDivÂ² Â³ ~ ElemDivÂ² O( Â³ r ElemDivÂ² O) Â³
where the union is a multiset union; that is, we keep all duplicate
members.

170

Advanced Linear Algebra

The Characteristic Polynomial
To continue our translation project, we need a definition. Recall that in the
characterization of cyclic modules in Theorem 6.17, we made reference to the
product of the elementary divisors, one from each associate class. Now that we
have singled out a special representative from each associate class, we can make
a useful definition.
Definition Let  Â BÂ²= Â³. The characteristic polynomial  Â²%Â³ of  is the
product of all of the elementary divisors of  :


 Â²%Â³ ~   Ã Â²%Â³
Ã

Hence,
degÂ² Â²%Â³Â³ ~ dimÂ²= Â³
Similarly, the characteristic polynomial 4 Â²%Â³ of a matrix 4 is the product of
the elementary divisors of 4 .
The following theorem describes the relationship between the minimal and
characteristic polynomials.
Theorem 7.8 Let  Â BÂ²= Â³.
1) (The Cayleyâ€“Hamilton theorem) The minimal polynomial of  divides the
characteristic polynomial of  :
 Â²%Â³ Â“  Â²%Â³
Equivalently,  satisfies its own characteristic polynomial, that is,
 Â² Â³ ~ 
2) The minimal polynomial




 Â²%Â³ ~ Ã Â²%Â³Ã„Ã Â²%Â³
and characteristic polynomial


 Â²%Â³ ~   Ã Â²%Â³
Ã

of  have the same set of prime factors  Â²%Â³ and hence the same set of
roots (not counting multiplicity).
We have seen that the multiset of elementary divisors forms a complete
invariant for similarity. The reader should construct an example to show that the
pair Â² Â²%Â³Ã  Â²%Â³Â³ is not a complete invariant for similarity, that is, this pair of

The Structure of a Linear Operator

171

polynomials does not uniquely determine the multiset of elementary divisors of
the operator  .
In general, the minimal polynomial of a linear operator is hard to find. One of
the virtues of the characteristic polynomial is that it is comparatively easy to
find and we will discuss this in detail a bit later in the chapter.
Note that since  Â²%Â³ Â“  Â²%Â³ and both polynomials are monic, it follows that
 Â²%Â³ ~  Â²%Â³

Â¯

degÂ² Â²%Â³Â³ ~ degÂ² Â²%Â³Â³

Definition A linear operator  Â BÂ²= Â³ is nonderogatory if its minimal
polynomial is equal to its characteristic polynomial:
 Â²%Â³ ~  Â²%Â³
or equivalently, if
degÂ² Â²%Â³Â³ ~ degÂ² Â²%Â³Â³
or if
degÂ² Â²%Â³Â³ ~ dimÂ²= Â³
Similar statements hold for matrices.

Cyclic and Indecomposable Modules
We have seen (Theorem 6.17) that cyclic submodules can be characterized by
their elementary divisors. Let us translate this theorem into the language of =
(and add one more equivalence related to the characteristic polynomial).
Theorem 7.9 Let  Â BÂ²= Â³ have minimal polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³
where  Â²%Â³ are distinct monic primes. The following are equivalent:
1) = is cyclic.
2) = is the direct sum
= ~ ÂºÂº# Â»Â» l Ã„ l ÂºÂº# Â»Â»
of  -cyclic submodules ÂºÂº# Â»Â» of order  Â²%Â³.
3) The elementary divisors of  are
ElemDivÂ² Â³ ~ Â¸ Â²%Â³Ã Ãƒ Ã  Â²%Â³Â¹
4)  is nonderogatory, that is,
 Â²%Â³ ~  Â²%Â³

172

Advanced Linear Algebra

Indecomposable Modules
We have also seen (Theorem 6.19) that, in the language of = , each prime factor
Â²%Â³ of the minimal polynomial  Â²%Â³ gives rise to a cyclic submodule > of =
of prime order Â²%Â³.
Theorem 7.10 Let  Â BÂ²= Â³ and let Â²%Â³ be a prime factor of  Â²%Â³. Then =
has a cyclic submodule > of prime order Â²%Â³.
For a module of prime order, we have the following.
Theorem 7.11 For a module > of prime order  Â²%Â³, the following are
equivalent:
1) > is cyclic
2) > is indecomposable
3)  Â²%Â³ is irreducible
4)  is nonderogatory, that is,  Â²%Â³ ~  Â²%Â³
5) dimÂ²> Â³ ~ degÂ²Â²%Â³Â³.
Our translation project is now complete and we can begin to look at issues that
are specific to the modules = .

Companion Matrices
We can also characterize the cyclic modules = via the matrix representations of
the operator  , which is obviously something that we could not do for arbitrary
modules. Let = ~ ÂºÂº#Â»Â» be a cyclic module, with order
 Â²%Â³ ~  b  % b Ã„ b c %c b %
and ordered  -cyclic basis
8 ~ 2#Ã  #Ã Ãƒ Ã  c #3
Then
 Â²  #Â³ ~  b #
for  Â  Â  c  and
 Â² c #Â³ ~   #
~ cÂ² b   b Ã„ b c  c Â³#
~ c # c   # c Ã„ c c  c #
and so

The Structure of a Linear Operator

v
x
x
Â´ Âµ8 ~ x 
x
Ã…
w

173

 Ã„  c y
 Ã„  c {
{
 Ã†
Ã… {
{
Ã… Ã†  cc2
 Ã„  cc z

This matrix is known as the companion matrix for the polynomial  Â²%Â³.
Definition The companion matrix of a monic polyomial
Â²%Â³ ~  b  % b Ã„ b c %c b %
is the matrix
v
x
x
*Â´Â²%Â³Âµ ~ x 
x
Ã…
w

 Ã„  c y
 Ã„  c {
{
 Ã†
Ã… {
{
Ã… Ã†  cc2
 Ã„  cc z

Note that companion matrices are defined only for monic polynomials.
Companion matrices are nonderogatory. Also, companion matrices are precisely
the matrices that represent operators on  -cyclic subspaces.
Theorem 7.12 Let Â²%Â³ Â - Â´%Âµ.
1) A companion matrix ( ~ *Â´Â²%Â³Âµ is nonderogatory; in fact,
( Â²%Â³ ~ ( Â²%Â³ ~ Â²%Â³
2) = is cyclic if and only if  can be represented by a companion matrix, in
which case the representing basis is  -cyclic.
Proof. For part 1), let ; ~ Â² Ã Ãƒ Ã  Â³ be the standard basis for -  . Since
 ~ (c  for  Â‚ , it follows that for any polynomial  Â²%Â³,
 Â²(Â³ ~ 

Â¯

 Â²(Â³ ~  for all 

Â¯

 Â²(Â³ ~ 

If Â²%Â³ ~  b  % b Ã„ b c %c b % , then
c

c

c

Â²(Â³ ~   (  b (  ~   b c   b ~ 
~

~

~

and so Â²(Â³ ~ , whence Â²(Â³ ~ . Also, if
Â²%Â³ ~  b  % b Ã„ b c %c b  %
is nonzero and has degree   , then
Â²(Â³ ~   b   b Ã„ b c  b  b Â£ 

174

Advanced Linear Algebra

since ; is linearly independent. Hence, Â²%Â³ has smallest degree among all
polynomials satisfied by ( and so Â²%Â³ ~ ( Â²%Â³. Finally,
degÂ²( Â²%Â³Â³ ~ degÂ²Â²%Â³Â³ ~ degÂ²( Â²%Â³Â³
For part 2), we have already proved that if = is cyclic with  -cyclic basis 8 ,
then Â´ Âµ8 ~ *Â´Â²%Â³Âµ. For the converse, if Â´ Âµ8 ~ *Â´Â²%Â³Âµ, then part 1) implies
that  is nonderogatory. Hence, Theorem 7.11 implies that = is cyclic. It is
clear from the form of *Â´Â²%Â³Âµ that 8 is a  -cyclic basis for = .

The Big Picture
If Ã  Â BÂ²= Â³, then Theorem 7.2 and the fact that the elementary divisors form
a complete invariant for isomorphism imply that
Â—

Â¯

= Âš =

Â¯

ElemDivÂ² Â³ ~ ElemDivÂ²Â³

Hence, the multiset of elementary divisors is a complete invariant for similarity
of operators. Of course, the same is true for matrices:
(Â—)

Â¯

-( Âš -)

Â¯

ElemDivÂ²(Â³ ~ ElemDivÂ²)Â³

where we write -( in place of -( .
The connection between the elementary divisors of an operator  and the
elementary divisors of the matrix representations of  is described as follows. If
( ~ Â´ Âµ8 , then the coordinate map 8 Â¢ = Âš -  is also a module isomorphism
8 Â¢ = Â¦ -( . Specifically, we have
8 Â²Â² Â³#Â³ ~ Â´Â² Â³#Âµ8 ~ Â²Â´ Âµ8 Â³Â´#Âµ8 ~ Â²(Â³8 Â²#Â³
and so 8 preserves - Â´%Âµ-scalar multiplication. Hence,
( ~ Â´ Âµ8 for some 8

Â¬

= Âš -(

For the converse, suppose that Â¢ = Âš -( . If we define  Â = by  ~  ,
where  is the th standard basis vector, then 8 ~ Â² Ã Ãƒ Ã  Â³ is an ordered
basis for = and  ~ 8 is the coordinate map for 8 . Hence, 8 is a module
isomorphism and so
8 Â² #Â³ ~ ( Â²8 #Â³
for all # Â = , that is,
Â´ #Âµ8 ~ ( Â²Â´#Âµ8 Â³
which shows that ( ~ Â´ Âµ8 .
Theorem 7.13 Let = be a finite-dimensional vector space over - . Let
Ã  Â BÂ²= Â³ and let (Ã ) Â C Â²- Â³.

The Structure of a Linear Operator

175

1) The multiset of elementary divisors (or invariant factors) is a complete
invariant for similarity of operators, that is,
 Â—  Â¯ = Âš =
Â¯ ElemDivÂ² Â³ ~ ElemDivÂ²Â³
Â¯ InvFactÂ² Â³ ~ InvFactÂ²Â³
A similar statement holds for matrices:
( Â— ) Â¯ -( Âš -)
Â¯ ElemDivÂ²(Â³ ~ ElemDivÂ²)Â³
Â¯ InvFactÂ²(Â³ ~ InvFactÂ²)Â³
2) The connection between operators and their representing matrices is
( ~ Â´ Âµ8 for some 8 Â¯ = Âš -(
Â¯ ElemDivÂ² Â³ ~ ElemDivÂ²(Â³
Â¯ InvFactÂ² Â³ ~ InvFactÂ²(Â³
Theorem 7.13 can be summarized in Figure 7.1, which shows the big picture.

W

V

similarity classes
of L(V)

VW

VV

isomorphism classes
of F[x]-modules

{ED1} {ED2}

Multisets of
elementary divisors

[W]B [V]B
[W]R [V]R

Similarity classes
of matrices
Figure 7.1

Figure 7.1 shows that the similarity classes of BÂ²= Â³ are in one-to-one
correspondence with the isomorphism classes of - Â´%Âµ-modules = and that these
are in one-to-one correspondence with the multisets of elementary divisors,
which, in turn, are in one-to-one correspondence with the similarity classes of
matrices.
We will see shortly that any multiset of prime power polynomials is the multiset
of elementary divisors for some operator (or matrix) and so the third family in

176

Advanced Linear Algebra

the figure could be replaced by the family of all multisets of prime power
polynomials.

The Rational Canonical Form
We are now ready to determine a set of canonical forms for similarity. Let
 Â BÂ²= Â³. The elementary divisor basis H for = that gives the primary cyclic
decomposition of = ,
= ~ Â²ÂºÂº#Ã Â»Â» l Ã„ l ÂºÂº#Ã Â»Â»Â³ l Ã„ l Â²ÂºÂº#Ã Â»Â» l Ã„ l ÂºÂº#Ã Â»Â»Â³
is the union of the bases
8Ã ~ Â²#Ã Ã  #Ã Ã Ãƒ Ã  Ã c #Ã Â³
and so the matrix of  with respect to H is the block diagonal matrix


Ã





Â´ ÂµH ~ diagÂ²*Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´  Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³ÂµÂ³
with companion matrices on the block diagonal. This matrix has the following
form.
Definition A matrix ( is in the elementary divisor form of rational canonical
form if
( ~ diag4*Â´ Â²%Â³ÂµÃ Ãƒ Ã *Â´ Â²%Â³Âµ5
where the  Â²%Â³ are monic prime polynomials.
Thus, as shown in Figure 7.1, each similarity class I contains at least one matrix
in the elementary divisor form of rational canonical form.
On the other hand, suppose that 4 is a rational canonical matrix


Ã





4 ~ diagÂ²*Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´  Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³ÂµÂ³
of size  d  . Then 4 represents the matrix multiplication operator 4 under
the standard basis ; on -  . The basis ; can be partitioned into blocks ;Ã
corresponding to the position of each of the companion matrices on the block
diagonal of 4 . Since


Â´4 OÂº;Ã Â» Âµ;Ã ~ *Â´ Ã Â²%Â³Âµ
it follows from Theorem 7.12 that each subspace Âº;Ã Â» is 4 -cyclic with monic

order  Ã Â²%Â³ and so Theorem 7.9 implies that the multiset of elementary

divisors of 4 is Â¸ Ã Â²%Â³Â¹.
This shows two important things. First, any multiset of prime power
polynomials is the multiset of elementary divisors for some matrix. Second, 4

The Structure of a Linear Operator

177

lies in the similarity class that is associated with the elementary divisors

Â¸ Ã Â²%Â³Â¹. Hence, two matrices in the elementary divisor form of rational
canonical form lie in the same similarity class if and only if they have the same
multiset of elementary divisors. In other words, the elementary divisor form of
rational canonical form is a set of canonical forms for similarity, up to order of
blocks on the block diagonal.
Theorem 7.14 (The rational canonical form: elementary divisor version) Let
= be a finite-dimensional vector space and let  Â BÂ²= Â³ have minimal
polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³
where the  Â²%Â³'s are distinct monic prime polynomials.
1) If H is an elementary divisor basis for = , then Â´ ÂµH is in the elementary
divisor form of rational canonical form:
Ã







Â´ ÂµH ~ diag4*Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´  Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³ÂµÃ Ãƒ Ã *Â´Ã Â²%Â³Âµ 5


where Ã Â²%Â³ are the elementary divisors of  . This block diagonal matrix
is called an elementary divisor version of a rational canonical form of  .
2) Each similarity class I of matrices contains a matrix 9 in the elementary
divisor form of rational canonical form. Moreover, the set of matrices in I
that have this form is the set of matrices obtained from 4 by reordering the
block diagonal matrices. Any such matrix is called an elementary divisor
verison of a rational canonical form of (.
3) The dimension of = is the sum of the degrees of the elementary divisors of
, that is,






dimÂ²= Â³ ~  degÂ² Ã Â³
~ ~

Example 7.1 Let  be a linear operator on the vector space s7 and suppose that
 has minimal polynomial
 Â²%Â³ ~ Â²% c Â³Â²% b Â³
Noting that % c  and Â²% b Â³ are elementary divisors and that the sum of the
degrees of all elementary divisors must equal , we have two possibilities:
1) % c Ã Â²% b 1Â³ Ã % b 
2) % c Ã % c Ã % c Ã Â²% b 1Â³
These correspond to the following rational canonical forms:

178

Advanced Linear Algebra

v
x
x
x
x
1) x 
x
x
x

w


























c

c




v
x
x
x
x
2) x 
x
x
x

w
















































y
{
{
{
{
{
{
{
{
c
z
y
{
{
{
{
c {
{
{
{
c
z

The rational canonical form may be far from the ideal of simplicity that we had
in mind for a set of simple canonical forms. Indeed, the rational canonical form
can be important as a theoretical tool, more so than a practical one.

The Invariant Factor Version
There is also an invariant factor version of the rational canonical form. We
begin with the following simple result.
Theorem 7.15 If Â²%Â³Ã Â²%Â³ Â - Â´%Âµ are relatively prime polynomials, then
*Â´Â²%Â³Â²%Â³Âµ Â— 6

*Â´Â²%Â³Âµ



*Â´Â²%Â³Âµ 7block

Proof. Speaking in general terms, if an  d  matrix ( has minimal
polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³
of degree equal to the size  of the matrix, then Theorem 7.14 implies that the
elementary divisors of ( are precisely
 Â²%Â³Ã Ãƒ Ã  Â²%Â³
Since the matrices *Â´Â²%Â³Â²%Â³Âµ and diagÂ²*Â´Â²%Â³ÂµÃ *Â´Â²%Â³ÂµÂ³ have the same size
 d  and the same minimal polynomial Â²%Â³Â²%Â³ of degree , it follows that
they have the same multiset of elementary divisors and so are similar.
Definition A matrix ( is in the invariant factor form of rational canonical
form if

The Structure of a Linear Operator

179

( ~ diag4*Â´  Â²%Â³ÂµÃ Ãƒ Ã *Â´  Â²%Â³Âµ5
where

b Â²%Â³ Â“

 Â²%Â³ for  ~ Ã Ãƒ Ã  c .

Theorem 7.15 can be used to rearrange and combine the companion matrices in
an elementary divisor version of a rational canonical form 9 to produce an
invariant factor version of rational canonical form that is similar to 9 . Also, this
process is reversible.
Theorem 7.16 (The rational canonical form: invariant factor version) Let
dimÂ²= Â³  B and suppose that  Â BÂ²= Â³ has minimal polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³
where the monic polynomials  Â²%Â³ are distinct prime (irreducible) polynomials
1) = has an invariant factor basis 8 , that is, a basis for which
Â´ Âµ8 ~ diag4*Â´  Â²%Â³ÂµÃ Ãƒ Ã *Â´  Â²%Â³Âµ5
where the polynomials  Â²%Â³ are the invariant factors of  and
b Â²%Â³ Â“  Â²%Â³. This block diagonal matrix is called an invariant factor
version of a rational canonical form of  .
2) Each similarity class I of matrices contains a matrix 9 in the invariant
factor form of rational canonical form. Moreover, the set of matrices in I
that have this form is the set of matrices obtained from 4 by reordering the
block diagonal matrices. Any such matrix is called an invariant factor
verison of a rational canonical form of (.
3) The dimension of = is the sum of the degrees of the invariant factors of  ,
that is,


dimÂ²= Â³ ~ degÂ²  Â³
~

The Determinant Form of the Characteristic Polynomial
In general, the minimal polynomial of an operator  is hard to find. One of the
virtues of the characteristic polynomial is that it is comparatively easy to find.
This also provides a nice example of the theoretical value of the rational
canonical form.
Let us first take the case of a companion matrix. If ( ~ *Â´ Â²%Â³Âµ is the
companion matrix of a monic polynomial
 Â²%Ã‚  Ã Ãƒ Ã c Â³ ~  b  % b Ã„ b c %c b %
then how can we recover Â²%Â³ ~ ( Â²%Â³ from *Â´Â²%Â³Âµ by arithmetic operations?

180

Advanced Linear Algebra

When  ~ , we can write  Â²%Â³ as
 Â²%Ã‚  Ã  Â³ ~  b  % b % ~ %Â²% b  Â³ b 
which looks suspiciously like a determinant:

% b  ?
 c
~ det6%0 c >
 c ?7
~ detÂ²%0 c *Â´ Â²%Â³ÂµÂ³

 Â²%Ã‚  Ã  Â³ ~ det>

%
c

So, let us define
(Â²%Ã‚  Ã Ãƒ Ã c Â³ ~ %0 c *Â´ Â²%Â³Âµ
 Ã„ 
v %
x c % Ã„ 
x
~ x  c Ã†
x
Ã…
Ã…
Ã† %
w 
 Ã„ c


y
{

{
Ã…
{
{
c
% b c z

where % is an independent variable. The determinant of this matrix is a
polynomial in % whose degree equals the number of parameters  Ã Ãƒ Ã c .
We have just seen that
detÂ²(Â²%Ã‚  Ã  Â³Â³ ~  Â²%Ã‚  Ã  Â³
and this is also true for  ~ . As a basis for induction, if
detÂ²(Â²%Ã‚  Ã Ãƒ Ã c Â³Â³ ~  Â²%Ã‚  Ã Ãƒ Ã c Â³
then expanding along the first row gives
detÂ²(Â²%Ã  Ã Ãƒ Ã  Â³Â³
v c
x 
~ % detÂ²(Â²%Ã  Ã Ãƒ Ã  Â³Â³ b Â²cÂ³  detx
Ã…
w 
~ % detÂ²(Â²%Ã  Ã Ãƒ Ã  Â³Â³ b 
~ %  Â²%Ã‚  Ã Ãƒ Ã  Â³ b 
~  % b  % b Ã„ b  % b %b b 
~ b Â²%Ã‚  Ã Ãƒ Ã  Â³
We have proved the following.

%
c
Ã…


Ã„  y
Ã†
{
{
Ã† %
Ã„ c zd

The Structure of a Linear Operator

181

Lemma 7.17 For any Â²%Â³ Â - Â´%Âµ,
detÂ²%0 c *Â´Â²%Â³ÂµÂ³ ~ Â²%Â³
Now suppose that 9 is a matrix in the elementary divisor form of rational
canonical form. Since the determinant of a block diagonal matrix is the product
of the determinants of the blocks on the diagonal, it follows that


detÂ²%0 c 9Â³ ~   Ã Â²%Â³ ~ 9 Â²%Â³
Ã

Moreover, if ( Â— 9, say ( ~ 7 97 c , then
detÂ²%0 c (Â³ ~ detÂ²%0 c 7 97 c Â³
~ det Â´7 Â²%0 c 9Â³7 c Âµ
~ detÂ²7 Â³detÂ²%0 c 9Â³detÂ²7 c Â³
~ detÂ²%0 c 9Â³
and so
detÂ²%0 c (Â³ ~ detÂ²%0 c 9Â³ ~ 9 Â²%Â³ ~ ( Â²%Â³
Hence, the fact that all matrices have a rational canonical form allows us to
deduce the following theorem.
Theorem 7.18 Let  Â BÂ²= Â³. If ( is any matrix that represents  , then
 Â²%Â³ ~ ( Â²%Â³ ~ detÂ²%0 c (Â³

Changing the Base Field
A change in the base field will generally change the primeness of polynomials
and therefore has an effect on the multiset of elementary divisors. It is perhaps a
surprising fact that a change of base field has no effect on the invariant factorsâ€”
hence the adjective invariant.
Theorem 7.19 Let - and 2 be fields with - Â‹ 2 . Suppose that the elementary
divisors of a matrix ( Â C Â²- Â³ are
Ã







7 ~ Â¸Ã Ã Ãƒ Ã   Ã Ãƒ Ã Ã Ã Ãƒ Ã Ã Â¹
Suppose also that the polynomials  can be further factored over 2 , say


Ã

 ~ ÃÃ Ã„Ã
where Ã is prime over 2 . Then the prime powers
 

Ã Ã

Ã Ã
8 ~ Â¸Ã
Ã Ãƒ Ã Ã









Ã Ã
Ã Ã
Ã Ãƒ Ã Ãƒ Ã Ã
Ã Ãƒ Ã Ã
Â¹


are the elementary divisors of ( over 2 .

182

Advanced Linear Algebra


Proof. Consider the companion matrix *Â´ Ã Â²%Â³Âµ in the rational canonical form
of ( over - . This is a matrix over 2 as well and Theorem 7.15 implies that


Ã Ã

 

*Â´ Ã Â²%Â³Âµ Â— diagÂ²*Â´ÃÃ Ã ÂµÃ Ãƒ Ã *Â´Ã ÂµÂ³
Hence, 8 is an elementary divisor basis for ( over 2 .
As mentioned, unlike the elementary divisors, the invariant factors are field
independent. This is equivalent to saying that the invariant factors of a matrix
( Â 4 Â²- Â³ are polynomials over the smallest subfield of - that contains the
entries of (Ã€
Theorem 7.20 Let ( Â C Â²- Â³ and let , Â‹ - be the smallest subfield of that contains the entries of (.
1) The invariant factors of ( are polynomials over , .
2) Two matrices (Ã ) Â C Â²- Â³ are similar over - if and only if they are
similar over , .
Proof. Part 1) follows immediately from Theorem 7.19, since using either 7 or
8 to compute invariant factors gives the same result. Part 2) follows from the
fact that two matrices are similar over a given field if and only if they have the
same multiset of invariant factors over that field.
Example 7.2 Over the real field, the matrix
(~6




c
7

is the companion matrix for the polynomial % b , and so
ElemDivs Â²(Â³ ~ Â¸% b Â¹ ~ InvFacts Â²(Â³
However, as a complex matrix, the rational canonical form for ( is
(~6





c 7

and so
ElemDivd Â²(Â³ ~ Â¸% c Ã % b Â¹

and

InvFactd Â²(Â³ ~ Â¸% b Â¹

Exercises
1.
2.

We have seen that any  Â BÂ²= Â³ can be used to make = into an - Â´%Âµmodule. Does every module = over - Â´%Âµ come from some  Â BÂ²= Â³?
Explain.
Let  Â BÂ²= Â³ have minimal polynomial
 Â²%Â³ ~  Â²%Â³Ã„ Â²%Â³

The Structure of a Linear Operator

183

where  Â²%Â³ are distinct monic primes. Prove that the following are
equivalent:
a) = is  -cyclic.
b) degÂ² Â²%Â³Â³ ~ dimÂ²= Â³.
c) The elementary divisors of  are the prime power factors  Â²%Â³ and so
= ~ ÂºÂº# Â»Â» l Ã„ l ÂºÂº# Â»Â»
is a direct sum of  -cyclic submodules ÂºÂº# Â»Â» of order  Â²%Â³.
3. Prove that a matrix ( Â C Â²- Â³ is nonderogatory if and only if it is similar
to a companion matrix.
4. Show that if ( and ) are block diagonal matrices with the same blocks, but
in possibly different order, then ( and ) are similar.
5. Let ( Â C Â²- Â³. Justify the statement that the entries of any invariant
factor version of a rational canonical form for ( are â€œrationalâ€ expressions
in the coefficients of (, hence the origin of the term rational canonical
form. Is the same true for the elementary divisor version?
6. Let  Â BÂ²= Â³ where = is finite-dimensional. If Â²%Â³ Â - Â´%Âµ is irreducible
and if Â² Â³ is not one-to-one, prove that Â²%Â³ divides the minimal
polynomial of  .
7. Prove that the minimal polynomial of  Â BÂ²= Â³ is the least common
multiple of its elementary divisors.
8. Let  Â BÂ²= Â³ where = is finite-dimensional. Describe conditions on the
minimal polynomial of  that are equivalent to the fact that the elementary
divisor version of the rational canonical form of  is diagonal. What can
you say about the elementary divisors?
9. Verify the statement that the multiset of elementary divisors (or invariant
factors) is a complete invariant for similarity of matrices.
10. Prove that given any multiset of monic prime power polynomials


Ã





4 ~ Â¸Ã Â²%Â³Ã Ãƒ Ã   Â²%Â³Ã Ãƒ Ã Ãƒ Ã Ã Â²%Â³Ã Ãƒ Ã Ã Â²%Â³Â¹
and given any vector space = of dimension equal to the sum of the degrees
of these polynomials, there is an operator  Â BÂ²= Â³ whose multiset of
elementary divisors is 4 .
11. Find all rational canonical forms Â²up to the order of the blocks on the
diagonal) for a linear operator on s6 having minimal polynomial
Â²% c 1Â³ Â²% b 1Â³ .
12. How many possible rational canonical forms (up to order of blocks) are
there for linear operators on s6 with minimal polynomial Â²% c 1Â³Â²% b 1Â³ ?
13. a) Show that if ( and ) are  d  matrices, at least one of which is
invertible, then () and )( are similar.

184

Advanced Linear Algebra
b) What do the matrices
(~>

c)





and
?

)~>





?

have to do with this issue?
Show that even without the assumption on invertibility the matrices
() and )( have the same characteristic polynomial. Hint: Write
( ~ 7 0Ã 8

where 7 and 8 are invertible and 0Ã is an  d  matrix that has the
 d  identity in the upper left-hand corner and 's elsewhere. Write
) Z ~ 8)7 . Compute () and )( and find their characteristic
polynomials.
14. Let  be a linear operator on -  with minimal polynomial
 Â²%Â³ ~ Â²% b 1Â³Â²% c 2Â³. Find the rational canonical form for  if
- ~ r, - ~ s or - ~ d.
15. Suppose that the minimal polynomial of  Â BÂ²= Â³ is irreducible. What can
you say about the dimension of = ?
16. Let  Â BÂ²= Â³ where = is finite-dimensional. Suppose that Â²%Â³ is an
irreducible factor of the minimal polynomial Â²%Â³ of  . Suppose further
that "Ã # Â = have the property that Â²"Â³ ~ Â²#Â³ ~ Â²%Â³. Prove that
" ~  Â² Â³# for some polyjomial  Â²%Â³ if and only if # ~ Â² Â³" for some
polynomial Â²%Â³.

Chapter 8

Eigenvalues and Eigenvectors

Unless otherwise noted, we will assume throughout this chapter that all vector
spaces are finite-dimensional.

Eigenvalues and Eigenvectors
We have seen that for any  Â BÂ²= Â³, the minimal and characteristic
polynomials have the same set of roots (but not generally the same multiset of
roots). These roots are of vital importance.
Let ( ~ Â´ Âµ8 be a matrix that represents  . A scalar  Â - is a root of the
characteristic polynomial  Â²%Â³ ~ ( Â²%Â³ ~ detÂ²%0 c (Â³ if and only if
detÂ²0 c (Â³ ~ 

(8.1)

that is, if and only if the matrix 0 c ( is singular. In particular, if dimÂ²= Â³ ~ ,
then (8.1) holds if and only if there exists a nonzero vector % Â -  for which
Â²0 c (Â³% ~ 
or equivalently,
( % ~  %
If Â´#Âµ8 ~ %, then this is equivalent to
Â´ Âµ8 Â´#Âµ8 ~ Â´#Âµ8
or in operator language,
 # ~ #
This prompts the following definition.
Definition Let = be a vector space over a field - and let  Â BÂ²= Â³.
1) A scalar  Â - is an eigenvalue (or characteristic value) of  if there
exists a nonzero vector # Â = for which

186

Advanced Linear Algebra

 # ~ #
In this case, # is called an eigenvector (or characteristic vector) of 
associated with .
2) A scalar  Â - is an eigenvalue for a matrix ( if there exists a nonzero
column vector % for which
(% ~ %
In this case, % is called an eigenvector (or characteristic vector) for (
associated with .
3) The set of all eigenvectors associated with a given eigenvalue  , together
with the zero vector, forms a subspace of = , called the eigenspace of  and
denoted by ; . This applies to both linear operators and matrices.
4) The set of all eigenvalues of an operator or matrix is called the spectrum
of the operator or matrix. We denote the spectrum of  by SpecÂ² Â³.
Theorem 8.1 Let  Â BÂ²= Â³ have minimal polynomial  Â²%Â³ and characteristic
polynomial  Â²%Â³.
1) The spectrum of  is the set of all roots of  Â²%Â³ or of  Â²%Â³, not counting
multiplicity.
2) The eigenvalues of a matrix are invariants under similarity.
3) The eigenspace ; of the matrix ( is the solution space to the homogeneous
system of equations
Â²0 c (Â³Â²%Â³ ~ 
One way to compute the eigenvalues of a linear operator  is to first represent 
by a matrix ( and then solve the characteristic equation
detÂ²%0 c (Â³ ~ 
Unfortunately, it is quite likely that this equation cannot be solved when
dimÂ²= Â³ Â‚ . As a result, the art of approximating the eigenvalues of a matrix is
a very important area of applied linear algebra.
The following theorem describes the relationship between eigenspaces and
eigenvectors of distinct eigenvalues.
Theorem 8.2 Suppose that  Ã Ãƒ Ã  are distinct eigenvalues of a linear
operator  Â BÂ²= Â³.
1) Eigenvectors associated with distinct eigenvalues are linearly independent;
that is, if # Â ; , then the set Â¸# Ã Ãƒ Ã # Â¹ is linearly independent.
2) The sum ; b Ã„ b ; is direct; that is, ; l Ã„ l ; exists.
Proof. For part 1), if Â¸# Ã Ãƒ Ã # Â¹ is linearly dependent, then by renumbering if
necessary, we may assume that among all nontrivial linear combinations of

Eigenvalues and Eigenvectors

187

these vectors that equal , the equation
 # b Ã„ b  # ~ 

(8.2)

has the fewest number of terms. Applying  gives
  # b Ã„ b   # ~ 

(8.3)

Multiplying (8.2) by  and subtracting from (8.3) gives
 Â² c  Â³# b Ã„ b  Â² c  Â³# ~ 
But this equation has fewer terms than (8.2) and so all of its coefficients must
equal . Since the  's are distinct,  ~  for  Â‚  and so  ~  as well. This
contradiction implies that the # 's are linearly independent.
The next theorem describes the spectrum of a polynomial Â² Â³ in  .
Theorem 8.3 (The spectral mapping theorem) Let = be a vector space over
an algebraically closed field - . Let  Â BÂ²= Â³ and let Â²%Â³ Â - Â´%Âµ. Then
SpecÂ²Â² Â³Â³ ~ Â²SpecÂ² Â³Â³ ~ Â¸Â²Â³ Â“  Â SpecÂ² Â³Â¹
Proof. We leave it as an exercise to show that if  is an eigenvalue of  , then
Â²Â³ is an eigenvalue of Â² Â³. Hence, Â²SpecÂ² Â³Â³ Â‹ SpecÂ²Â² Â³Â³. For the reverse
inclusion, let  Â SpecÂ²Â² Â³Â³, that is,
Â²Â² Â³ c Â³# ~ 
for # Â£ . If
Â²%Â³ c  ~ Â²% c  Â³ Ã„Â²% c  Â³
where  Â - , then writing this as a product of (not necessarily distinct) linear
factors, we have
Â² c  Â³Ã„Â² c  Â³Ã„Â² c  Â³Ã„Â² c  Â³# ~ 
(The operator   is written  for convenience.) We can remove factors from
the left end of this equation one by one until we arrive at an operator  (perhaps
the identity) for which # Â£  but Â² c  Â³# ~ . Then # is an eigenvector
for  with eigenvalue  . But since Â² Â³ c  ~ , it follows that
 ~ Â² Â³ Â Â²SpecÂ² Â³Â³. Hence, SpecÂ²Â² Â³Â³ Â‹ Â²SpecÂ² Â³Â³.

The Trace and the Determinant
Let - be algebraically closed and let ( Â C Â²- Â³ have characteristic
polynomial
( Â²%Â³ ~ % b c %c b Ã„ b  % b 
~ Â²% c  Â³Ã„Â²% c  Â³

188

Advanced Linear Algebra

where  Ã Ãƒ Ã  are the eigenvalues of (. Then
( Â²%Â³ ~ detÂ²%0 c (Â³
and setting % ~  gives
detÂ²(Â³ ~ c ~ Â²cÂ³c  Ã„
Hence, if - is algebraically closed then, up to sign, detÂ²(Â³ is the constant term
of ( Â²%Â³ and the product of the eigenvalues of (, including multiplicity.
The sum of the eigenvalues of a matrix over an algebraically closed field is also
an interesting quantity. Like the determinant, this quantity is one of the
coefficients of the characteristic polynomial (up to sign) and can also be
computed directly from the entries of the matrix, without knowing the
eigenvalues explicitly.
Definition The trace of a matrix ( Â C Â²- Â³, denoted by trÂ²(Â³, is the sum of
the elements on the main diagonal of (.
Here are the basic propeties of the trace. Proof is left as an exercise.
Theorem 8.4 Let (Ã ) Â C Â²- Â³.
1) trÂ²AÂ³ ~  trÂ²(Â³, for  Â - .
2) trÂ²( b )Â³ ~ trÂ²(Â³ b trÂ²)Â³.
3) trÂ²()Â³ ~ trÂ²)(Â³.
4) trÂ²()*Â³ ~ trÂ²*()Â³ ~ trÂ²)*(Â³. However, trÂ²()*Â³ may not equal
trÂ²(*)Â³.
5) The trace is an invariant under similarity.
6) If - is algebraically closed, then trÂ²(Â³ is the sum of the eigenvalues of (,
including multiplicity, and so
trÂ²(Â³ ~ cc
where ( Â²%Â³ ~ % b c %c b Ã„ b  % b  .
Since the trace is invariant under similarity, we can make the following
definition.
Definition The trace of a linear operator  Â BÂ²= Â³ is the trace of any matrix
that represents  .
As an aside, the reader who is familar with symmetric polynomials knows that
the coefficients of any polynomial
Â²%Â³ ~ % b c %c b Ã„ b  % b 
~ Â²% c  Â³Ã„Â²% c  Â³

